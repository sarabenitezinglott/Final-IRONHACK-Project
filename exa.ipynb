{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\saraa\\miniconda3\\envs\\final\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\saraa\\miniconda3\\envs\\final\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\saraa\\miniconda3\\envs\\final\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\saraa\\miniconda3\\envs\\final\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Found 14 images belonging to 2 classes.\n",
      "Found 8 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saraa\\AppData\\Local\\Temp\\ipykernel_7052\\2287471577.py:75: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:From c:\\Users\\saraa\\miniconda3\\envs\\final\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\saraa\\miniconda3\\envs\\final\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7058 - accuracy: 0.6000"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected value for `steps_per_epoch`. Received value is 0. Please check the docstring for `model.fit()` for supported values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\saraa\\Final-IRONHACK-Project\\exa.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m train_generator \u001b[39m=\u001b[39m train_datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     train_data_dir,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     target_size\u001b[39m=\u001b[39m(img_width, img_height),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     class_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m validation_generator \u001b[39m=\u001b[39m test_datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     validation_data_dir,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     target_size\u001b[39m=\u001b[39m(img_width, img_height),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     class_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit_generator(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     train_generator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49mnb_train_samples \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m batch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mnb_validation_samples \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m batch_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saraa/Final-IRONHACK-Project/exa.ipynb#W0sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m model\u001b[39m.\u001b[39msave_weights(\u001b[39m'\u001b[39m\u001b[39mfirst_try.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\saraa\\miniconda3\\envs\\final\\lib\\site-packages\\keras\\src\\engine\\training.py:2913\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2901\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2902\u001b[0m \n\u001b[0;32m   2903\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2904\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2905\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2906\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2907\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2908\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2909\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2910\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2911\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2912\u001b[0m )\n\u001b[1;32m-> 2913\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   2914\u001b[0m     generator,\n\u001b[0;32m   2915\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   2916\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   2917\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2918\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   2919\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   2920\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   2921\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   2922\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2923\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2924\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2925\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2926\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   2927\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m   2928\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\saraa\\miniconda3\\envs\\final\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\saraa\\miniconda3\\envs\\final\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1275\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[0;32m   1272\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m model\n\u001b[0;32m   1274\u001b[0m \u001b[39mif\u001b[39;00m steps_per_epoch \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1275\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnexpected value for `steps_per_epoch`. Received value is 0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1277\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease check the docstring for `model.fit()` for supported \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mvalues.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[0;32m   1281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_epoch \u001b[39m=\u001b[39m steps_per_epoch\n\u001b[0;32m   1283\u001b[0m \u001b[39m# `steps_per_execution_value` is the cached initial value.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[39m# `steps_per_execution` is mutable and may be changed by the DataAdapter\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[39m# to handle partial executions.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected value for `steps_per_epoch`. Received value is 0. Please check the docstring for `model.fit()` for supported values."
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = \"D:/bootcamp/original/try_train/\"\n",
    "validation_data_dir = \"D:/bootcamp/original/try_val/\"\n",
    "nb_train_samples = 14\n",
    "nb_validation_samples = 8\n",
    "epochs = 2\n",
    "batch_size = 10\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 3000000000 \n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = int(np.ceil(x_train.shape[0] / batch_size) )\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
